{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anneal_epoch': 25,\n",
      " 'anneal_rate': 0.5,\n",
      " 'babi_task': 7,\n",
      " 'batch_size': 32,\n",
      " 'checkpoint_dir': './checkpoints',\n",
      " 'data_dir': './bAbI/en-valid',\n",
      " 'edim': 20,\n",
      " 'init_lr': 0.01,\n",
      " 'init_mean': 0.0,\n",
      " 'init_std': 0.1,\n",
      " 'is_test': True,\n",
      " 'lin_start': False,\n",
      " 'max_grad_norm': 40,\n",
      " 'max_sentences': 34,\n",
      " 'max_words': 16,\n",
      " 'mem_size': 50,\n",
      " 'nepoch': 100,\n",
      " 'nhop': 3,\n",
      " 'nwords': 44,\n",
      " 'show_progress': False}\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints\\MemN2N.model-3276\n",
      "{'test_loss': 1.7564343185424804, 'validation_loss': 3.9531608009338379}\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints\\MemN2N.model-3276\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from data import read_data, pad_data, depad_data\n",
    "from model import MemN2N\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer(\"edim\", 20, \"internal state dimension [20]\")\n",
    "flags.DEFINE_integer(\"nhop\", 3, \"number of hops [3]\")\n",
    "flags.DEFINE_integer(\"mem_size\", 50, \"maximum number of sentences that can be encoded into memory [50]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 32, \"batch size to use during training [32]\")\n",
    "flags.DEFINE_integer(\"nepoch\", 100, \"number of epoch to use during training [100]\")\n",
    "flags.DEFINE_integer(\"anneal_epoch\", 25, \"anneal the learning rate every <anneal_epoch> epochs [25]\")\n",
    "flags.DEFINE_integer(\"babi_task\", 7, \"index of bAbI task for the network to learn [1]\")\n",
    "flags.DEFINE_float(\"init_lr\", 0.01, \"initial learning rate [0.01]\")\n",
    "flags.DEFINE_float(\"anneal_rate\", 0.5, \"learning rate annealing rate [0.5]\")\n",
    "flags.DEFINE_float(\"init_mean\", 0., \"weight initialization mean [0.]\")\n",
    "flags.DEFINE_float(\"init_std\", 0.1, \"weight initialization std [0.1]\")\n",
    "flags.DEFINE_float(\"max_grad_norm\", 40, \"clip gradients to this norm [40]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"./bAbI/en-valid\", \"dataset directory [./bAbI/en_valid]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"./checkpoints\", \"checkpoint directory [./checkpoints]\")\n",
    "flags.DEFINE_boolean(\"lin_start\", False, \"True for linear start training, False for otherwise [False]\")\n",
    "flags.DEFINE_boolean(\"is_test\", False, \"True for testing, False for training [False]\")\n",
    "flags.DEFINE_boolean(\"show_progress\", False, \"print progress [False]\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "word2idx = {}\n",
    "max_words = 0\n",
    "max_sentences = 0\n",
    "\n",
    "if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "    os.makedirs(FLAGS.checkpoint_dir)\n",
    "\n",
    "train_stories, train_questions, max_words, max_sentences = read_data('{}/qa{}_train.txt'.format(FLAGS.data_dir, FLAGS.babi_task), word2idx, max_words, max_sentences)\n",
    "valid_stories, valid_questions, max_words, max_sentences = read_data('{}/qa{}_valid.txt'.format(FLAGS.data_dir, FLAGS.babi_task), word2idx, max_words, max_sentences)\n",
    "test_stories, test_questions, max_words, max_sentences = read_data('{}/qa{}_test.txt'.format(FLAGS.data_dir, FLAGS.babi_task), word2idx, max_words, max_sentences)\n",
    "\n",
    "pad_data(train_stories, train_questions, max_words, max_sentences)\n",
    "pad_data(valid_stories, valid_questions, max_words, max_sentences)\n",
    "pad_data(test_stories, test_questions, max_words, max_sentences)\n",
    "\n",
    "idx2word = dict(zip(word2idx.values(), word2idx.keys()))\n",
    "FLAGS.nwords = len(word2idx)\n",
    "FLAGS.max_words = max_words\n",
    "FLAGS.max_sentences = max_sentences\n",
    "\n",
    "pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = MemN2N(FLAGS, sess)\n",
    "    model.build_model()\n",
    "\n",
    "    if FLAGS.is_test:\n",
    "        model.run(valid_stories, valid_questions, test_stories, test_questions)\n",
    "    else:\n",
    "        model.run(train_stories, train_questions, valid_stories, valid_questions)\n",
    "    \n",
    "    predictions, target = model.predict(train_stories, train_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 25\n",
    "\n",
    "depad_data(train_stories, train_questions)\n",
    "\n",
    "question = train_questions[index]['question']\n",
    "answer = train_questions[index]['answer']\n",
    "story_index = train_questions[index]['story_index']\n",
    "sentence_index = train_questions[index]['sentence_index']\n",
    "\n",
    "story = train_stories[story_index][:sentence_index + 1]\n",
    "\n",
    "story = [list(map(idx2word.get, sentence)) for sentence in story]\n",
    "question = list(map(idx2word.get, question))\n",
    "prediction = [idx2word[np.argmax(predictions[index])]]\n",
    "answer = list(map(idx2word.get, answer))\n",
    "\n",
    "print('Story:')\n",
    "pp.pprint(story)\n",
    "print('\\nQuestion:')\n",
    "pp.pprint(question)\n",
    "print('\\nPrediction:')\n",
    "pp.pprint(prediction)\n",
    "print('\\nAnswer:')\n",
    "pp.pprint(answer)\n",
    "print('\\nCorrect:')\n",
    "pp.pprint(prediction == answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
